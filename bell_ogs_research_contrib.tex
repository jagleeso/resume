% resume.tex
%
% (c) 2002 Matthew Boedicker <mboedick@mboedick.org> (original author) http://mboedick.org
% (c) 2003-2007 David J. Grant <davidgrant-at-gmail.com> http://www.davidgrant.ca
%
% This work is licensed under the Creative Commons Attribution-ShareAlike 3.0 Unported License. To view a copy of this license, visit http://creativecommons.org/licenses/by-sa/3.0/ or send a letter to Creative Commons, 171 Second Street, Suite 300, San Francisco, California, 94105, USA.
%\documentclass[letterpaper,11pt]{article}
\documentclass[letterpaper,11pt]{article}

%-----------------------------------------------------------
%Margin setup

\setlength{\voffset}{0.1in}
\setlength{\paperwidth}{8.5in}
\setlength{\paperheight}{11in}
\setlength{\headheight}{0in}
\setlength{\headsep}{0in}
\setlength{\textheight}{11in}
\setlength{\textheight}{9.5in}
% \setlength{\topmargin}{-0.50in}
\setlength{\textwidth}{7in}
\setlength{\topskip}{0in}

% % \setlength{\topmargin}{-1.0in}
% \setlength{\topmargin}{-0.25in}
% % \setlength{\bottommargin}{-0.50in}
% \setlength{\oddsidemargin}{-0.25in}
% \setlength{\evensidemargin}{-0.25in}

%% FORMAT %%
% https://www.sgs.utoronto.ca/awards-funding/scholarships-awards/ontario-graduate-scholarship-application-instructions/?highlight=OGS#section_5
% Body text in a minimum 12 pt Arial, Times New Roman, or similar font
% Single-spaced, with no more than 6 lines of type per inch
% All margins set at a minimum of 3/4â€³ (1.87 cm)

\RequirePackage{enumitem}
\RequirePackage{anysize}
% \marginsize{left}{right}{top}{bottom}
% OGS / Bell scholarship: All margins set at a minimum of 3/4" (1.87 cm)
%\marginsize{0.75in}{0.75in}{0.25in}{0.25in}
\marginsize{0.75in}{0.75in}{0.75in}{0.75in}

%%
%% ATC 2020 template (Usenix 2019)
%%
% refs and bib
\RequirePackage{cite}               % order multiple entries in \cite{...}
\RequirePackage{breakurl}           % break too-long urls in refs
\RequirePackage{url}                % allow \url in bibtex for clickable links
\RequirePackage{xcolor}             % color definitions, to be use for...
\RequirePackage[]{hyperref}         % ...clickable refs within pdf...
\hypersetup{                    % ...like so
  colorlinks,
  linkcolor={green!80!black},
  citecolor={red!70!black},
  urlcolor={blue!70!black}
}

%\RequirePackage{amssymb}
%\RequirePackage{amsmath}
%\RequirePackage{amsthm}
%\RequirePackage{xparse}
%\RequirePackage{tikz}

% \asPercent
\RequirePackage{pgfmath}
\RequirePackage{siunitx}

%-----------------------------------------------------------
%\RequirePackage{fullpage}
% \RequirePackage{shading}
\RequirePackage{bold-extra}
%\textheight=9.0in
\pagestyle{empty}
\raggedbottom
\raggedright
\setlength{\tabcolsep}{0in}

%-----------------------------------------------------------
%Custom commands

\newcommand{\company}[1]{
    \textbf{#1}
}

\newcommand{\heading}[1]{
    \noindent
    \textsc{\textbf{#1}}
}

\newcommand{\asPercent}[1]{\pgfmathparse{100*#1}\num[round-mode=places,round-precision=1]{\pgfmathresult}\%}

% title for the root sections (experience, education, etc) of the resume
\newcommand*\resheading[1]{\subsection*{\heading{#1}}\vspace{0.3em}\nopagebreak[4]}
% \newcommand\resheading[1]{\vspace{-0.3em}}

\newcommand{\resitem}[1]{\item #1 \vspace{-2pt}}
% \newcommand{\resheading}[1]{{\large \parashade[.95]{roundcorners}{\textbf{#1 \vphantom{p\^{E}}}}}}
\newcommand{\ressubheading}[4]{
\begin{tabular*}{6.5in}{l@{\extracolsep{\fill}}r}
    
		\company{#1} & #2 \\
		\textit{#3} & \textit{#4} \\
\end{tabular*}\vspace{-6pt}}
\newcommand{\mscphdheading}[6]{
\begin{tabular*}{6.5in}{l@{\extracolsep{\fill}}r}
    
		\company{#1} & #2 \\
		\textit{#3} & \textit{#4} \\
		\textit{#5} & \textit{#6} \\
\end{tabular*}\vspace{-6pt}}
\newcommand{\sickkids}[6]{
\begin{tabular*}{6.5in}{l@{\extracolsep{\fill}}r}
		\company{#1} & #2 \\
		\textit{#3} & \textit{#4} \\
		 & \textit{#5} \\
		 & \textit{#6} \\
\end{tabular*}\vspace{-6pt}}
% \newcommand{\ressubheadingnodate}[4]{
% \begin{tabular*}{6.5in}{l@{\extracolsep{\fill}}r}
% 		\textbf{#1} \\
% \end{tabular*}\vspace{-6pt}}
\newcommand{\ressubheadingnodate}[1]{
		% \textbf{#1} \\
		#1 \\
}
%-----------------------------------------------------------


\begin{document}

% \begin{tabular*}{7in}{l@{\extracolsep{\fill}}r}
% \textbf{\Large James Gleeson}  & 647-298-9193\\
% 499 Martha Street & jagleeso@gmail.com \\
% Burlington, ON L7R 2R1 \\
% \end{tabular*}
% \\

% \textbf{\large James Gleeson -- Research Contributions, Relevant Experiences \& Activities}
% \begin{tabular*}{7in}{l@{\extracolsep{\fill}}r}
% \textbf{Research area:} Software & 647-298-9193 \\
%     May 13, 2021 & \url{https://jagleeso.github.io}, \href{mailto:jagleeso@gmail.com}{jagleeso@gmail.com} \\
% \end{tabular*}
% \\

\textbf{\large James Gleeson -- Research Contributions, Relevant Experiences \& Activities (2021)}
\begin{tabular*}{7in}{l@{\extracolsep{\fill}}r}
\textbf{Research area:} Software & \url{https://jagleeso.github.io}, \href{mailto:jagleeso@gmail.com}{jagleeso@gmail.com} \\
\end{tabular*}
\\

 
\hrule

\vspace{0.1in}


\heading{Research Contributions}



\setlength{\parindent}{1.5em}

\begin{itemize}[leftmargin=*]
\item 
    \noindent
        \textbf{\href{https://arxiv.org/abs/2102.04285}{RL-Scope: Cross-Stack Profiling for Deep Reinforcement Learning Workloads}} \\
    \noindent
        \textit{\underline{James Gleeson}, Srivatsan Krishnan, Moshe Gabel, Vijay Janapa Reddi, Eyal de Lara, Gennady Pekhimenko} \\
    \noindent
    Fourth Conference on Machine Learning and Systems (\href{https://mlsys.org/Conferences/2021}{MLSys 2021})
\end{itemize}
\vspace{-1em}
%
The latest research in my PhD has focussed on building an open-source profiling tool called RL-Scope for 
performing cross-stack analysis of RL training workloads.  
Unlike more commonly studied GPU-bound supervised learning workloads, RL training workloads must collect training data at runtime through simulation leading to a large CPU-bound component.
RL-Scope provides a fine-grained breakdown of CPU/GPU time into GPU-side kernel execution, and CPU-side execution of high-level language code (Python) and low-level framework code (CUDA API calls, TensorFlow framework).
Using RL-Scope, we discovered at least 38.1\% and at most 74.2\% of training time in RL workloads is CPU-bound in simulation; hence, future ML systems research must optimize the CPU-bound portion of the ML software stack to speedup RL.
We also surveyed scale-up workloads that parallelize multiple inference requests to attempt to take advantage of GPU hardware parallelism, and discovered that coarse-grained GPU utilization metrics in off-the-shelf profiling tools led developers to make poor use of the available GPU hardware parallelism.

\begin{itemize}[leftmargin=*]
\item 
    \noindent
    \textbf{MoIL: Enabling Efficient Incremental Training on Edge Devices} \\
    \noindent
    \textit{Jiacheng Yang, \underline{James Gleeson}, Mostafa Elhoushi, Gennady Pekhimenko.} \\
    \noindent
    Hardware Aware Efficient Training Workshop (\href{https://haet2021.github.io}{HAET 2021}).

\end{itemize}
\vspace{-1em}
%
% we challenged the status quo approach of training models in the cloud and deploying them on the device.
In this workshop paper, we explore optimizations required for enabling training \emph{on-device}, rather than in the cloud.
Training models on-device (e.g., mobile devices) opens opportunities such as model personalization based on user-specific data, robustness to intermittent network connectivity, and keeping data secure and private on-device.
To achieve this goal, we train the model \emph{incrementally} on-device.  
The model is pre-trained in the cloud on a large curated global dataset.
Incremental training continues on-device using local user data, and a small portion of the global dataset to avoid catastrophic forgetting ($29.7\times$ reduction in training time compared the full global dataset).
To reduce compute overhead, we only train the last layer of the model, which indirectly also preserves performance on the global dataset while increasing accuracy on local user data (further $36.6\times$ reduction in training time).
Finally, we further reduce compute overhead by caching feature maps of intermediate layers whose weights are frozen (further $7.9\times$ reduction in training time).  Together, these optimizations make training on-device realistic by reducing training time on a Samsung S10e from 7 months to a mere 38.8 minutes.
In this paper, I took an advisory role, helping with ideation process, writing the final workshop draft, and recommending future directions for the student to take.


\begin{itemize}[leftmargin=*]
\item 
    \noindent
    \textbf{\href{https://dl.acm.org/doi/10.1145/3078468.3078478}{Crane: Fast and Migratable GPU Passthrough for OpenCL Applications}} \\
    \noindent
    \textit{\underline{James Gleeson}, Daniel Kats, Charlie Mei, Eyal de Lara} \\
    \noindent
    10th ACM International Systems and Storage Conference (\href{https://www.systor.org/2017/}{SYSTOR 2017}).
    \\
    \textbf{\href{https://www.usenix.org/conference/hotcloud17/program/presentation/gleeson}{Heterogeneous GPU Reallocation}} \\
    \noindent
    \textit{\underline{James Gleeson}, Eyal de Lara} \\
    \noindent
    9th USENIX Workshop on Hot Topics in Cloud Computing (\href{https://www.usenix.org/conference/hotcloud17}{HotCloud 2017})
\end{itemize}
\vspace{-1em}
%
The first publication of my PhD focussed on enabling efficient live migration of GPU compute workloads running 
inside a virtual machine instance.  Device passthrough using IOMMUs in today's cloud data center deployments 
allows assignment of GPUs to VM instances with zero overhead, but this simultaneously prevents hypervisor 
device interposition needed for enabling VM migration (e.g. during machine maintenance).  Our SYSTOR 2017 
paper on Crane showed how to enable live migration with low-overhead ($< 5.25\%$) by transparently 
implementing state-tracking and interposition at the user-level GPU programming API (OpenCL), and enabling 
continued use of a GPU during live migration by forwarding GPU API calls to a proxy domain running on the 
source machine.  In a followup HotCloud 2017 paper, we illustrated how GPU API level virtualization can be 
used to enable live migration between heterogeneous GPU models, enabling dynamic reallocation of GPUs in 
the cloud for use cases such as spot instances.


\begin{itemize}[leftmargin=*]
\item 
    \noindent
        \textbf{\href{https://dl.acm.org/doi/10.1145/2694344.2694380}{Protecting Data on Smartphones and Tablets from Memory Attacks}} \\
    \noindent
    \textit{Patrick J. Colp, Jiawen Zhang, \underline{James Gleeson}, Sahil Suneja, Eyal de Lara, Himanshu Raj, Stefan Saroiu, Alec Wolman.} \\
    \noindent
    20th International Conference on Architectural Support for Programming Languages and Operating Systems (\href{http://asplos15.bilkent.edu.tr}{ASPLOS 2015})
\end{itemize}
\vspace{-0.9em}
%
I measured the performance and energy tradeoffs of protecting against 
cold boot attacks on Android through the encryption of sensitive processes.  To 
support background applications running while encrypted, I swap encrypted DRAM 
pages into and out of a tightly managed decrypted secure memory.
I extended encryption of user-level application pages to kernel stacks 
to prevent leaking AES state, tracking page accesses inside the kernel using 
in-kernel page faults.



\vspace{1em}
\heading{Relevant Experience \& Activities}

%%
%% INSTRUCTIONS: https://www.sgs.utoronto.ca/awards-funding/scholarships-awards/ontario-graduate-scholarship-application-instructions/?highlight=OGS#section_0
%%
%%   Part 2. Relevant Experience & Activities
%%   Describe the research/academic abilities that you have gained through your past research/academic experience, including special projects, honours/masterâ€™s thesis, co-op reports, etc. If you have relevant work experience, discuss the relevance of that experience to your proposed field of study/research and any benefits you gained from it.
%%
%%   This section may also be used to describe your training relative to your proposed research such as knowledge gained through lived experience and traditional teachings.
%%
%%   Relevant Activities
%%
%%   Describe your professional, academic and extracurricular activities, interactions and collaborations that best demonstrate your communication, interpersonal and leadership skills. Examples of these include:
%%
%%   teaching, mentoring, supervising and/or coaching
%%   managing projects
%%   participating in science and/or research promotion
%%   community outreach, volunteer work and/or civic engagement
%%   chairing committees and/or organizing conferences and meetings
%%   participating in departmental or institutional organizations, associations, societies and/or clubs
%%

\vspace{1em}
\noindent
\textbf{Internships:} Between finishing my Master's and beginning my PhD, I did two back-to-back internships to inform and enrich my academic pursuits with industrial motivations.
In the Summer of 2015, I interned worked at Samsung Research America in Mountain View, CA, working on Samsung's ARM hypervisor based KNOX secure smartphone product.  
I designed and implemented a low-overhead and secure OS-level defense against kernel control-flow integrity attacks that attempts to achieve privilege escalation by overwriting return addresses to chain together Turing complete 
computations (return-oriented programming attacks).  
This work culminated in a \href{https://patents.google.com/patent/US20170140148A1/en}{software patent}.
To learn more about areas beyond the mobile security from my Masters work, in Fall 2015 I interned at Microsoft Research in Redmond, Washington where I worked on FaRM distributed shared memory computing platform.
% (extending work from their NSDI 2014 paper).
The original implementation of fault tolerance in FaRM stores triply replicated copies of every object in the system, requiring a total of three RDMA writes to the primary the two backup servers.
I investigated implementing erasure coding to reduce storage needed for storing replicas.
I considered both block-based and object-based erasure coding schemes, settling on a block-based scheme to minimize coordination amongst replicas on the critical path of transactions.

\vspace{1.0em}
\noindent
\textbf{Reading Group and Social Events:} I have been instrumental in organizing a faculty-wide biweekly reading group where students from various groups in our department can learn to critically read papers of their choosing and find overlapping interests with potential collaborators.
This has had a positive impact especially during the COVID-19 pandemic, where incoming students have had a hard time getting to know the systems research group (SysNet) at UofT.
Beyond just our reading group, I have proactively organized a faculty-wide \href{https://discord.com}{Discord} voice-chat server for socialization, and \href{https://gather.town}{GatherTown} events to allow students to still interact with each other in these socially distanced times.

\vspace{1.0em}
\noindent
\textbf{Shadow Program Committee:} 
I regularly participate in writing paper reviews for a variety of top-tier systems conferences
(e.g., 
\href{https://www.microarch.org/micro54}{MICRO 2021},
\href{https://www.usenix.org/conference/osdi21}{OSDI 2021},
\href{https://mlsys.org/Conferences/2020}{MLSys 2020},
\href{https://iscaconf.org/isca2020}{ISCA 2020}).
This review process closely resembles a full PC meeting, whereby three students in our group discuss and collaborate to write a final paper review that we submit to our advisor for approval and final submission to the conference. 
%%
% Here is a list of some of the conferences I have reviewed papers for: 
% \href{https://www.microarch.org/micro54}{MICRO 2021},
% \href{https://www.usenix.org/conference/osdi21}{OSDI 2021},
% \href{https://mlsys.org/Conferences/2020}{MLSys 2020},
% \href{https://iscaconf.org/isca2020}{ISCA 2020},
% \href{https://cgo-conference.github.io/cgo2020}{CGO 2020},
% \href{https://www.eurosys2020.org}{EuroSys 2020},
% \href{https://www.hpca-conf.org/2020}{HPCA 2020},
% \href{https://www.microarch.org/micro52}{MICRO 2019},
% \href{https://ics19.eecis.udel.edu}{ICS 2019},
% \href{https://www.usenix.org/conference/atc19}{ATC 2019},
% \href{https://iscaconf.org/isca2019}{ISCA 2019},
% \href{https://mlsys.org/Conferences/2019}{MLSys 2019}.

% \nocite{*}
% \bibliographystyle{plain}
% \pagebreak
% \resheading{References}
% \begingroup
% \renewcommand{\section}[2]{}%
% \bibliography{references}
% \endgroup


\end{document}
